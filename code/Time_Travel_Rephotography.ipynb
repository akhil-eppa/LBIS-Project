{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrsFo-ryivcl"
      },
      "source": [
        "#Time-Travel Rephotography\n",
        "\n",
        "**Author**: [Xuan Luo](https://roxanneluo.github.io/)\n",
        "\n",
        "[[Project Page](https://time-travel-rephotography.github.io/)]\n",
        "\n",
        "DISCLAIMER : This notebook is taken from the above website. It is an implementation by the authors of our base paper, Time-Travel Rephotography. We have used this as the base working to reproduce the results along with a few examples of our own. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4lY7kJQNuXz"
      },
      "source": [
        "## Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33lkSUgGtH2t"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "pwd = os.getcwd().split('/')[-1]\n",
        "if pwd != \"Time-Travel-Rephotography\":\n",
        "  !!git clone  --depth 1 --recurse-submodules --shallow-submodules \\\n",
        "    https://github.com/Time-Travel-Rephotography/Time-Travel-Rephotography.github.io.git Time-Travel-Rephotography\n",
        "  %cd Time-Travel-Rephotography\n",
        "else:\n",
        "  print(\"Catalogue has been created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Cuch83ignd"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyekuBL7i-Vf"
      },
      "outputs": [],
      "source": [
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ1fl5qIjE4z"
      },
      "source": [
        "## Download models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIDDOutMM6kz"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "set -exo\n",
        "mkdir -p checkpoint\n",
        "mkdir -p checkpoint/encoder\n",
        "mkdir -p third_party/face_parsing/res/cp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn7nrAMTwaB9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9Slmk3SmoEH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "def downloadModel(filename, filepath, target_path):\n",
        "  print(f\"path:{filepath}  name:{filename}\")\n",
        "  path = hf_hub_download(filepath, filename, use_auth_token=TOKEN)\n",
        "  print(f\"src:{path} target:{target_path}\")\n",
        "  file = path.split('/')[-1]\n",
        "  with open(path, 'rb')as rstream:\n",
        "    container = rstream.read()\n",
        "    path1 = os.path.join(target_path,file)\n",
        "    with open(path1, 'wb') as wstream:\n",
        "        wstream.write(container)\n",
        "\n",
        "target_path = os.getcwd()\n",
        "TOKEN = \"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\"\n",
        "modelList = [(\"e4e_ffhq_encode.pt\", \"feng2022/Time-TravelRephotography_e4e_ffhq_encode\", f\"{target_path}/checkpoint\"),\n",
        "      (\"stylegan2-ffhq-config-f.pt\", \"feng2022/Time-TravelRephotography_stylegan2-ffhq-config-f\", f\"{target_path}/checkpoint\"),\n",
        "      (\"vgg_face_dag.pt\", \"feng2022/Time-TravelRephotography_vgg_face_dag\", f\"{target_path}/checkpoint\"),\n",
        "      (\"checkpoint_b.pt\", \"feng2022/Time_TravelRephotography_checkpoint_b\", f\"{target_path}/checkpoint/encoder\"),\n",
        "      (\"checkpoint_g.pt\", \"feng2022/Time_TravelRephotography_checkpoint_g\", f\"{target_path}/checkpoint/encoder\"),\n",
        "      (\"checkpoint_gb.pt\", \"feng2022/Time_TravelRephotography_checkpoint_gb\", f\"{target_path}/checkpoint/encoder\"),\n",
        "      (\"79999_iter.pth\", \"feng2022/Time-TravelRephotography_79999_iter\", f\"{target_path}/third_party/face_parsing/res/cp\")]\n",
        "for model in modelList:\n",
        "  downloadModel(model[0], model[1], model[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAqQCGAGpN6-"
      },
      "source": [
        "If the script above fails, which is largely due to exceeding download quota, try run the script below.\n",
        "\n",
        "```\n",
        "!./scripts/download_checkpoints.sh\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYo5FzLnnG1v"
      },
      "source": [
        "## Configure Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCruJr3Oac2Y"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "\n",
        "def upload_files(input_dir=Path()):\n",
        "  from google.colab import files\n",
        "  input_dir.mkdir(parents=True, exist_ok=True)\n",
        "  prev_dir = os.getcwd()\n",
        "  os.chdir(input_dir)\n",
        "  uploaded = files.upload()\n",
        "  os.chdir(prev_dir)\n",
        "  return [input_dir / k for k in uploaded.keys()]\n",
        "\n",
        "\n",
        "# @title Path to the input image\n",
        "input_path = \"dataset/example5.png\"  # @param {type: 'string'}\n",
        "\n",
        "# @markdown Do you want to upload and process your own image instead?\n",
        "upload = False #@param {type:\"boolean\"}\n",
        "\n",
        "if upload:\n",
        "  from tools.data import align_images as align\n",
        "  # upload image\n",
        "  upload_dir = Path(\"dataset/unaligned\")\n",
        "  paths = upload_files(upload_dir)\n",
        "  # align image\n",
        "  aligned_dir = Path(\"dataset/\")\n",
        "  args = align.parse_args([\n",
        "    str(upload_dir),\n",
        "    str(aligned_dir),\n",
        "  ])\n",
        "  align.main(args)\n",
        "  input_path = aligned_dir / f\"{paths[0].stem}_01.png\"\n",
        "\n",
        "print(f\"input_path = '{input_path}'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlfY7kuyqYgC"
      },
      "outputs": [],
      "source": [
        "# @title Spectral sensitivity of the negative\n",
        "# @markdown The `spectral_sensitivity` can be `'b'` (blue-sensitive), `'gb'` (orthochromatic), or `'g'` (panchromatic). \n",
        "# @markdown You can roughly estimate the spectral_sensitivity of your photo as follows. Use the blue-sensitive model for photos before 1873, manually select between blue-sensitive and orthochromatic for images from 1873 to 1906 and among all models for photos taken afterwards.\n",
        "spectral_sensitivity = \"gb\"  # @param [\"b\", \"gb\", \"g\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpMMTmHvqtEQ"
      },
      "outputs": [],
      "source": [
        "# @title Estimated blur radius of the input photo\n",
        "gaussian_radius =   0.75# @param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_download_model_command(file_id, file_name):\n",
        "    \"\"\" Get wget download command for downloading the desired model and save to directory ../pretrained_models. \"\"\"\n",
        "    current_directory = os.getcwd()\n",
        "    save_path = os.path.join(os.path.dirname(current_directory), \"pixel2style2pixel\", \"pretrained_models\")\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    url = r\"\"\"wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id={FILE_ID}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id={FILE_ID}\" -O {SAVE_PATH}/{FILE_NAME} && rm -rf /tmp/cookies.txt\"\"\".format(FILE_ID=file_id, FILE_NAME=file_name, SAVE_PATH=save_path)\n",
        "    return url\n",
        "\n",
        "MODEL_PATHS = {\n",
        "    \"ffhq_encode\": {\"id\": \"1bMTNWkh5LArlaWSc_wa8VKyq2V42T2z0\", \"name\": \"psp_ffhq_encode.pt\"}\n",
        "}\n",
        "\n",
        "path = MODEL_PATHS[\"ffhq_encode\"]\n",
        "download_command = get_download_model_command(file_id=path[\"id\"], file_name=path[\"name\"])\n",
        "!{download_command}"
      ],
      "metadata": {
        "id": "5N1fuu9AUdCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3weHAclSgSTB"
      },
      "source": [
        "## Run\n",
        "After finishing the optimization, check the `results/` folder for the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHkm-TWYoTPs"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload\n",
        "from argparse import Namespace\n",
        "from projector import (\n",
        "    ProjectorArguments,\n",
        "    main,\n",
        ")\n",
        "\n",
        "args = ProjectorArguments().parse(\n",
        "    args=[str(input_path)], \n",
        "    namespace=Namespace(\n",
        "        spectral_sensitivity=spectral_sensitivity,\n",
        "        encoder_ckpt=f\"checkpoint/encoder/checkpoint_{spectral_sensitivity}.pt\",\n",
        "        e4e_ckpt=\"checkpoint/e4e_ffhq_encode.pt\",\n",
        "        encoder_name=spectral_sensitivity,\n",
        "        gaussian=gaussian_radius,\n",
        "        log_visual_freq=1000,\n",
        "        log_dir=\"log/\",\n",
        "        results_dir=\"results/\"\n",
        "))\n",
        "main(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dWnF32HIb5nD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}